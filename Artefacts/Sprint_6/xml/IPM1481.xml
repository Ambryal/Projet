<article><preamble>IPM1481.pdf</preamble>
<titre>Information Processing and Management</titre>
<auteurs></auteurs>
<abstract>CORTEX(Torres-Moreno, St-Onge, Gagnon, El-Bèze, &amp; Bellot, 2009, 2001), an efﬁcient state-of-art summa-
rization system, in order to retain the more informative segments of the CL.
Each document of the application is transmitted to theCORTEX</abstract>
<introduction>11
list (for example, that is, each of, etc.), numbers (in numeric and/or textual format), symbols such as ‘‘$’’, ‘‘#’’,
‘‘
⁄
’’. Finally, lemmatisation
12
is performed to signiﬁcantly reduce the size of the lexicon. All these processes allow us to repre-
sent the collection of documents through the bag-of-words paradigm (a matrix of frequencies of terms (columns) for each can-
didate answer (rows)). To improve ﬁltering, we tried parsing applications with different signiﬁcant terms (like ‘‘Personal
Information’’, ‘‘Education’’, ’’Work Experience’’, etc.) and extract only paragraphs with the relevant information, but initial tests
showed a decline in results due to the great variability of signiﬁant terms and order of paragraphs.
4.1.2. Proximity between applications and job offer using similarity measures After the step of linguistic pre-processing, each document is transformed into a vector with weights characterizing the
frequency of terms
Tf . Some tests with
Tf-idf (Salton &amp; Mcgill, 1986) were made but they offered no improvement. We have
established a strategy using measures of similarity, to rank all applications in relation to a job offer. We combined different
similarity measures between the candidate’s answers (CV and CL) and the associated job offer. We decided to use several
similarity measures as deﬁned in Bernstein, Kaufmann, Kiefer, and Bnrki (2005): Cosine (Eq. (1)), which calculates the angle
between job offer and each candidate answer, Minkowski distances (Eq. (2)) (
p = 1 for Manhattan,
p = 2 for Euclidean). The
last measure used is Okabis (Eq. (3)) (Bellot &amp; El-Bèze, 2001). Based on the formula of Okapi (Robertson, Walker, Jones, Han-
cock-Beaulieu, &amp; Gatford, 1994), this measure is often used in Information Retrieval. To combine these measures, we use an
Algorithm Decision (AD) (Boudin &amp; Torres Moreno, 2007), which weights the values obtained by each measure of similarity.
Several other similarity measures (Overlap, Enertex, Needleman-Wunsch, Jaro-Winkler, Jensen-Shannon divergence) have
been tested but they are not retained in this study, because the results obtained were disapointing. All measures used
and their combinations are described in Kessler, Béchet, Roche, El-Bèze, and Torres-Moreno (2008a).
candidatures 
ranking
Internet
Job offer
processing
Job offer 
publication
CV
Splitting 
candidate’s
e-mails
Profiling
Module 1
Module 2
Module 3
Description
Title
Mission
Profile
Candidate
companies
LIA
CORTEX
System
CL
Relevance 
Feedback
Fig. 1.
System overview.
11
http://sites.univ-provence.fr/veronis/donnees/index.html.
12
Lemmatisation ﬁnds the root of verbs and transforms plural and/or feminine words into masculine singular form. So we conﬂate terms
developer,
development, developing, to develop
into develop.
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
1127
Author&apos;s personal copy
cosine
ð
j
;
d
Þ ¼
P
n
i
¼
1
j
i
�
d
i
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
n
i
¼
1
j
2
i
�
P
n
i
¼
1
d
2
i
q
ð
1
Þ
Minkowski
ð
j
;
d
Þ ¼
1
1
þ
P
n
i
¼
1
j
j
i
�
d
i
j
p
�
�
1
p
ð
2
Þ
Okabis
ð
j
;
d
Þ ¼
P
i
2
d
\
j
P
n
i
¼
1
j
i
�
d
i
P
n
i
¼
1
j
i
�
d
i
þ
ﬃﬃﬃﬃ
j
d
j
p
M
d
ð
3
Þ where
j is a job offer,
d is a candidate answer,
i a term,
j
i and
d
i occurrence of
i respectively in
j and
d , and
M
d their average
size.
4.1.3. Relevance Feedback We previously changed the system to incorporate a process of Relevance Feedback (Sparck Jones, 1970). Relevance Feed-
back is a standard method used particulary for manual query reformulation. For example, the user carefully checks the an-
swer set resulting from an initial query, and then reformulates the query. Rocchio’s algorithm (Rocchio, 1971) and variations
have found wide usage in Information Retrieval and related areas such as Text Categorisation (Joachims, 1997). Relevance
Feedback has been proposed in Smyth and Bradley (2003) to help the user to ﬁnd a job with server logs from the jobFinder
site.
13
In our system, Relevance Feedback takes into account the recruiting consultant’s choice during a ﬁrst evaluation of a few
CVs. Our goal is not a system capable of ﬁnding the best candidate, but a system capable of reproducing the judgement of the
recruitment consultant. It is critical for recruiters not to miss a promising candidate that they may have unfortunately rejected.
The goal of this Relevance Feedback approach is to help them to avoid this kind of error. We assume that successful candidates
have similar proﬁles or, at least, that they have much in common. This approach uses documents returned in response to a ﬁrst
request to improve the search results (Salton &amp; Buckley, 1990). In this case, we randomly take a few candidate answers (1–6 in
our experiments) from all relevant candidate answers. These selected candidate answers are added to the job offer. So, we use
manual Relevance Feedback to reﬂect user judgements in the resulting ranking. We increase the vector representation with the
terms from the candidates considered relevant by a recruitment consultant. The system will recompute the similarity between
the candidate’s answer that we evaluate and the job offer enriched with relevant candidates. This allows
Sim
0
to be recalculed
for each measure of similarity between the application evaluated and the job offer expanded by
relevant
applications of the
relevance feedback process:
Sim
0
measure
ð
j
;
d
Þ ¼
Sim
measure
ð
j
;
d
k
p
1
k � � � k
p
n
Þ
ð
4
Þ where
j is a job offer,
d is a candidate’s response,
p
i is a
relevant candidate’s response,
n are numbers of retained applications
for Relevance Feedback and
k is the concatenation operator.
The results, presented in Kessler et al. (2009) and hereafter called
ISMIS Result showed an improvement in the quality of
the ranking obtained for each application added to the process of relevance feedback. However, we suspected that a lot of
unnecessary information was still kept in the evaluation and we wanted to use a ﬁlter to take into account the content of
sentences. Each document contains additional information (hobbies, greeting and complimentary close, etc.) and standard
pre-processing only partially removes it. The idea was to use a system of automatic summarization, coupled to E-Gen, as
a powerful ﬁlter capable of removing non-essential information contained in CV and Cover Letters.
4.2. The
CORTEX
summarization system Automatic summarization is useful to cope with ever increasing volumes of information. An abstract is, by far, the most
concrete and recognized kind of text condensation. However, the CV is already a kind of summary, with a very important
structure. We suspect that the ﬁltering system of automatic summarization may not be useful in this case. Since the CL is
in free text, we used
CORTEX (Torres-Moreno, St-Onge, Gagnon, El-Bèze, &amp; Bellot, 2009, 2001), an efﬁcient state-of-art summa-
rization system, in order to retain the more informative segments of the CL.
Each document of the application is transmitted to the
CORTEX system which provides a summary based on the requested
size.
CORTEX is a document extract summarization system using an optimal decision algorithm that combines several metrics.
These metrics result from processing statistical and informational algorithms on the document vector space representation.
Fig. 2 presents an overview of the system.
The idea is to represent the text in an appropriate vectorial space and apply numeric processings to it. In order to reduce
complexity, a pre-processing of the document is performed: words are ﬁltered, lemmatized, and stemmed. Based on the
terms that remain in the text after ﬁltering, a frequency matrix
c is built in the following way: Each element
c
l
i of this matrix
represents the number of occurrences of the word
i in the sentence
l .
13
JobFinder (http://www.jobﬁnder.com).
1128
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
Author&apos;s personal copy
c
¼
c
1
1
c
1
2
. . .
c
1
i
. . .
c
1
N
L
c
2
1
c
2
2
. . .
c
2
i
. . .
c
2
N
L
...
...
...
...
...
..
.
c
l
1
c
l
2
. . .
c
l
i
. . .
c
l
N
L
...
...
...
...
...
..
.
c
N
S
1
c
N
S
2
. . .
c
N
S
i
. . .
c
N
S
N
L
2
6666666666664
3
7777777777775
;
c
l
i
2 f
0
;
1
;
2
;
. . .
g
ð
5
Þ Another matrix
n , called
a binary virtual or
presence matrix , is deﬁned as:
n
l
i
¼
1
if
c
l
i
–
0
0
elsewhere
(
)
ð
6
Þ Each line of these matrices represents a sentence of the text. Matrices
c and
c
T are the frequency matrix of the sentences
and frequency matrix of the titles respectively.
The
CORTEX system can use up to
C = 11 metrics (Torres-Moreno, Velazquez-Morales, &amp; Meunier, 2002) to evaluate the sen-
tence’s relevance.
The system scores each sentence with a decision algorithm which relies on the normalized metrics. Two averages are cal-
culated, a positive
k
s &gt; 0.5, and a negative
k
s &lt; 0.5 tendency (the case
k
s = 0.5 is ignored). The following algorithm combines
the vote of each metric:
P
s
a
¼
P
C
v
¼
1
k
v
��
s
��
�
0
:
5
�
;
�
k
v
��
s
��
&gt;
0
:
5
P
s
b
¼
P
C
v
¼
1
0
:
5
�
k
v
��
s
��
�
;
�
k
v
��
s
��
&lt;
0
:
5
C is the number of metrics and
v is the index of the metrics. The value given to each sentence
s is calculated with:
if
P
s
a
&gt;
P
s
b
�
� then
Score
cortex
s
¼ 0
:</introduction>
<corps>5 þ
P
s
a
=
C : retain
s else
Score
cortex
s
¼ 0
: 5
�
P
s
b
=
C : not retain
s
Fig. 2.
CORTEX
overview.
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
1129
Author&apos;s personal copy The sentences are then ranked according to the obtained values. Depending on the desired compression rate, the sorted
sentences will be used to produce the summary. The
CORTEX system is applied to each document (Cover Letter) and a sum-
mary is generated by concatenating high-scoring sentences. We generated several abstracts with a variable compression rate
(5%, 10%, 20%,
. . . , 50%, 75% of the size of the documents, in sentences) in order to test the impact of our powerful ﬁlter on the
E-Gen system. The entire process chain is illustrated in Fig. 1. The best compression rates are generally with 30% (Torres-
Moreno et al., 2009). The results are presented in Section 5.3.
5. Experiments We selected a data subset from Aktor’s database composed of 1917 candidates. This subset is called the
Mission Corpus . It
has a size of 10 MB of raw texts and contains 1,375,000 words. The
Mission Corpus is composed of a set of 12 job offers cov-
ering various themes (jobs in accountancy, business, computer science, etc.) and their candidates. Each Job Offer is associated
with at least six candidates identiﬁed as
relevant . As described in Kessler et al. (2008a), each document is segmented to keep
the relevant parts (we remove the description of the company (D) for the job offer). Each candidate answer is tagged as
rel-
evant or
irrelevant . A
relevant value corresponds to a potential candidate for a speciﬁc job chosen by the recruiting consul-
tant. An
irrelevant value is associated with an unsuitable candidate for the job (this is a decision made by the manager of a
human resources company). Our study was conducted on French job offers because the French market represents Aktor’s
main activity. Table 1 shows a few statistics about the
Mission Corpus .
5.1. Example of CL summaries Fig. 3 presents
14
an example of an original Cover Letter and Fig. 4. Its corresponding summary
15
generated by the
CORTEX
sys-
tem with a 30% compression rate (in number of sentences). All the documents of
Mission Corpus were previously made anonymous. We observe that the original CL contains a
number of useless information for ranking, such as addresses, phone numbers or form of address at the beginning or
end of the letter. The last part of the CL is generally as ‘‘Yours faithfully’’, ‘‘Yours sincerely’’, ‘‘Best regards’’, all of which
represent irrelevant information. We further observe in Fig. 4 that the summary obtained with
CORTEX removes all this
information.
5.2. Experimental protocol We measured the similarity between a job offer and its candidate’s responses. These measures (Section 4.1.2) rank the
candidate’s answers by computing a similarity between a job offer and the associated candidate answers. We use the
ROC curves to evaluate the quality of the ranking obtained. ROC curves (Ferri, Flach, &amp; Hernandez-Orallo, 2002) come from
the ﬁeld of signal processing. They are used in medicine to evaluate the validity of diagnostic tests. In our case, ROC curves
show the rate of irrelevant candidate answers on the X-axis and the rate of relevant candidate answers on the Y-axis. The
14
Pierre ASPRE
26 years old
19 Verdun street 92870 Vannes
06-06-06-06-06.
Subject: collaboration offer
Vannes, November 27th, 2008
Dear Sir,
The Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing proﬁtability. With his legal knowledge in tax
and social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices and
knowing how to deal with the late settlement of invoices.
Therefore I offer my skills. They allow me to:
– Manage with rigueur the accounts of a company.
– Ensure legal compliance activities (payroll, tax billing etc.).
– Provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.
I suggest we meet to discuss all the terms of our future cooperation.
I look forward to hearing from you.
Best regards.
Pierre ASPRE.
15
Pierre ASPRE
Subject: collaboration offer
The Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing proﬁtability. With his legal knowledge in tax
and social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices and
knowing how to deal with late settlement of invoices.
– ensure legal compliance activities (payroll, tax billing etc.).
– provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.
1130
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
Author&apos;s personal copy Area Under the Curve (AUC) can be interpreted as the effectiveness of a measurement of interest. In the case of candidate
answers ranking, a perfect ROC curve corresponds to obtaining all relevant candidate answers at the beginning of the list
and all irrelevant ones at the end. This situation corresponds to AUC = 1. The diagonal line corresponds to the performance
of a random system, progress of the rate of relevant candidates being accompanied by an equivalent degradation in the rate
of irrelevant candidates. This situation corresponds to AUC = 0.5, as explained in Fawcett (2006). An effective measurement
Fig. 3.
Example of full Cover Letter.
Table 1
Mission corpus statistics.
Number
Job title
Number of candidate answers
Number of
Relevant
Irrelevant
34861
Sales engineer
40
14
26
31702
Accountant, department suppliers
55
23
32
33633
Sales engineer
65
18
47
34865
Accountant assistant
67
10
57
34783
Accountant assistant
108
9
99
33746
3 chefs
116
60
56
33553
Trade commissioner
117
17
100
33725
Urban sales consultant
118
43
75
31022
Recruitment assistant
221
28
193
31274
Accountant assistant junior
224
26
198
34119
Sales assistant
257
10
247
31767
Accountant assistant junior
437
51
386
Total
1917
323
1594
Fig. 4.
Summary of Cover Letter (see Fig. 3) at a 30% compression rate.
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
1131
Author&apos;s personal copy of interest to order candidate’s answers consists in obtaining the highest AUC value. This is strictly equivalent to minimizing
the sum of the ranks of the relevant candidate’s answers. ROC curves are resistant to imbalance (for example, an imbalance
in the number of positive and negative examples) (Roche &amp; Kodratoff, 2006). For each job offer, we evaluated the quality of
the ranking obtained by this method. Candidate answers considered are only those composed of CV and CL.
5.3. Results In this section, we present the results obtained by combining the
CORTEX system with the E-Gen ranking application.
CORTEX was used as an additional ﬁlter which generates a summary of each document before E-Gen evaluation. We keep the struc-
ture of data for job offers as described in Kessler et al. (2008a). A job offer is composed of a Description (D), a Title (T), a
Mission (M), and a Proﬁle (P). For these experiments, we use two combinations of a job offer content, keeping only Title, Mis-
sion, Proﬁle (TMP) and all information of a job offer (DTMP). Results are presented in Tables 2 and 3. Each column presents a
part of the application with different sizes of summaries for each line (75%, 50%,
. . . , 5%). Full text is a result obtained with
100% of the document and was published previously in Kessler et al. (2008a, 2009).
Table 2 presents results obtained for each part of the application separately. We observe that AUC of CVs remains below
the baseline whatever the percentage of compression. We notice however a gradual decrease in AUC scores depending on the
percentage of compression. We explain this by the fact that a CV is already a summary of the most important information
about the candidates and thereby attempting to summarize degrades ﬁnal results. We apply the same process with cover
letters. Performance is still low overall for CLs in comparison with CVs, however, there is a slight increase in AUC scores with
a compression rate of 30%. We explain these results by particular information contained in a cover letter such as the form of
address at the beginning or end of the letter (see Fig. 4) which are noise for the ranking system of E-Gen. Results with TMP
segmentation (i.e. conserving only Title, Mission, and Proﬁle of job offer) are of better quality.
Table 3 presents the results obtained by combining both parts of the application. Full text values are computed with the
whole documents of the application. The ﬁrst two columns show the results obtained by combining the summary of the CV
and the CL. We observe again a deterioration in the results when trying to summarize the CV. Even if results are lower, it
should be noted, however, that the best score is again obtained at 30%. The last two columns present the results with a sum-
marized CL and the full CV. We observe an overall improvement of the AUC score and the best results with a compression
rate of 30% of the Cover Letter.
Next step is to combine summaries of the cover letter, which suppresses noise and enriches the offer with the Relevance
Feedback process. Table 4 presents the results obtained with different sizes of Relevance Feedback (RF1 corresponds to one
application added to the job offer, RF2 two applications added to the job offer, etc.). Each application added with the rele-
vance feedback process consists in a full CV and a summary of the cover letter with a compression rate of 30%. A random
distribution of applications produces an AUC approximately at 0.5 like explained in Fawcett (2006). We compare
ISMIS Result with those obtained using a summary of the cover letter. Each test is carried out 100 times with a random distribution of
relevant applications for Relevance Feedback. Then we compute an average of AUC scores obtained (the curve shows the
Table 2
Results of CL or CV according to the compression rate of Cortex and part of job offer (with or without Description part).
CORTEX
compression rate (%)
CV + DTMP
CV + TMP
CL + DTMP
CL + TMP
100 (full text)
0.622
0.648
0.567
0.560
75
0.565
0.575
0.563
0.556
50
0.558
0.569
0.553
0.560
40
0.552
0.565
0.561
0.565
30
0.549
0.560
0.569
0.571
20
0.520
0.558
0.564
0.566
10
0.559
0.559
0.543
0.554
5
0.550
0.542
0.521
0.523
Table 3
Results for CV and cover letter according to the compression rate.
CORTEX
compression rate (%)
CV and CL summaries
Full CV and CL summary
DTMP
TMP
DTMP
TMP
100 (full text)
0.634
0.642
0.634
0.642
75
0.521
0.581
0.639
0.641
50
0.556
0.551
0.643
0.649
40
0.544
0.568
0.643
0.651
30
0.570
0.587
0.646
0.653
20
0.569
0.533
0.641
0.652
10
0.564
0.534
0.631
0.645
5
0.546
0.547
0.638
0.649
1132
R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135
Author&apos;s personal copy average for each size). In fact, we compute the Residual Ranking (Billerbeck &amp; Zobel, 2006): Documents that are used for Rel-
evance Feedback are removed from the collection before ranking with the reformulated query. We assume that the Rele-
vance Feedback process would behave as a reinforcement learning (Sutton &amp; Barto, 1998) but it is impossible to
experiment RF
n with
n &gt; 6 with this corpus because the number of
relevant candidates is too small for some job offers
(see Table 1). We observe a slight improvement in results for almost any size of Relevance Feedback. We are conscious that
the performance gain is low, however, it conﬁrms previous results on the Cover Letter. Fig. 5 shows this improvement. This
ﬁgure conﬁrms that the addition of just one relevant candidate (RF1) enables the AUC value to be enhanced (i.e. an improve-
ment of 0.5–1.2%). This Relevance Feedback (i.e. RF1) is not very time-consuming for the expert.
Fig. 6 shows detailed results of one test. For clarity reasons, we present only 3 of the 12 jobs of our dataset in order to
compare results with and without
CORTEX (for each job,
RFC are AUC scores with
CORTEX and
RF without
CORTEX ).
For standard system, we observe a positive progress from 1% to 10% for 10 jobs between RF0 and RF1 (e.g. ﬁve jobs have
an improvement between 5% and 10%). Note that between RF0 and RF6, 6 jobs have a signiﬁcant positive progress between
10% and 12%. The combination of the E-Gen and
CORTEX systems improve standard system results for ﬁve jobs from 1% to 5%
between RF0 and RF1. Between RF0 and RF6, the Cortex version improves E-Gen’s results for eight jobs from 1% to 5%.
The study of the results shows that job offer 31702 contains some relevant applications with a bad labeling (CV are la-
beled CL and CL are only a hyperlink to a CV). The reduction of information on the main document of the application leads
the system version using summaries to degrade the AUC scores. Job offer 34861 shows a good improvement with each size of
relevance feedback (RF0:0.65, RF1:0.70, RF6:0.73) and with
CORTEX (RF0:0.68, RF1:0.72, RF6:0.79). The detailed study of re-
sults shows that job offer 33746 contains some empty applications labeled relevant. This leads the system with and without
CORTEX to degrade ﬁnal results. In the same way, an application added without CL explains the identical score in RF2 between
RF and RFC for job offer 31274.
6. Conclusion and future work</corps>
<discussion>N/A</discussion>
<conclusion>Job offer processing is a difﬁcult and highly subjective task. The retrieval of relevant information concerning job descrip-
tions and skills is not a trivial task (Loth et al., 2010) and results on this type of document have been quite low (Clech &amp;Table 4Comparison of AUC score for each size of Relevance Feedback withCORTEXsummarization system.Size of Relevance FeedbackISMIS resultFull CV and CL summary 30% compression rate
Random distribution
0.500
0.500
RF0
0.642
0.653
RF1
0.654
0.658
RF2
0.657
0.659
RF3
0.659
0.661
RF4
0.659
0.659
RF5
0.660
0.662
RF6
0.6610.663
Fig. 5.Results of Relevance Feedback with and without summaries of CL.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351133Author&apos;s personal copy</conclusion>
<biblio>Audras, I., &amp; Ganascia, J.-G. (2006). Apprentissage du frantais langue TtrangFre et TALN: Analyses de corpus Tcrits a l’aide d’outils d’extraction automatique
du langage. In J.-M. Viprey (Ed.),8Fmes JournTes d’Analyse de DonnTes Textuelles(pp. 67–78). Univ. de Franche ComtT, Besanton 2006.
Bellot, P., &amp; El-Bèze, M. (2001). Classiﬁcation et segmentation de textes par arbres de dTcision. InTSI(Vol. 20, pp. 107–134). HermFs.
Ben Abdessalem Karaa, W. (2009). Web-based recruiting: A framework for cvs handling. InSecond international conference on web and information
technologies ‘‘ICWIT’09’’, kerkennah Island, Sfax, Tunisia, June 12–14(pp. 395–406).
Bernstein, A., Kaufmann, E., Kiefer, C., &amp; Bnrki, C. (2005). Simpack: A generic java library for similarity measures in ontologies. Tech. rep., University of Zurich
Department of Informatics.
Billerbeck, B., &amp; Zobel, J. (2006). Efﬁcient query expansion with auxiliary data structures.Information Systems, 31(7), 573–584.
Boudin, F., &amp; Torres Moreno, J. M. (2007). Neo-cortex: A performant user-oriented multi-document summarization system. InCICLing(pp. 551–562).
Bourse, M., LeclFre, M., Morin, E., &amp; Trichet, F. (2004). Human resource management and semantic web technologies. InICTTA 2004 Damascus Syria(pp. 641–
642).
Cazalens, S., &amp; Lamarre, P. (2001). An organization of internet agents based on a hierarchy of information domains. InProceedings MAAMAW’2001, Annecy,
France(pp. 573–584).
Clech, J., &amp; Zighed, D. A. (2003). Data mining et analyse des cv: une expérience et des perspectives. InEGC’03 Revue des Sciences et Technologies de
l’Information(Vol. 17, pp. 83–92). Lyon.
Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F. M., Mongiello, M., &amp; Mottola, M. (2003). A formal approach to ontology-based semantic match of skills
descriptions.Journal of Universal Computer Science, Special issue on Skills Management, 9, 1437–1454.
Dorn, J., &amp; Naz, T. (2007). Meta-search in human resource management. InProceedings of 4th international conference on knowledge systems ICKS’07
Bangkok,Thailand(pp. 105–110).
Enrica, A., &amp; Iezzi, D. F. (2006). Recruitment via web and information technology: A model for ranking the competences in job market. InJADT’2006,
Besanton, France(pp. 79–88).
Fan, R.-E., Chen, P.-H., &amp; Lin, C.-J. (2005). Working set selection using the second order information for training SVM.Journal of Machine Learning Research,
1889–1918.
Fawcett, T. (2006). An introduction to ROC analysis.Pattern Recognition Letters, 27, 861–874.
Ferri, C., Flach, P., &amp; Hernandez-Orallo, J. (2002). Learning decision trees using the area under the ROC curve. InProceedings of ICML 2002: Sydney, NSW,
Australia(pp. 139–146).
Gorenak, I., &amp; Mlaker KaF, S. S. O. (2010). Cross-cultural comparison of online job advertisements.JLST, Journal of Logistics and Sustainable Transport, 2, 37–52.RF0
RF1
RF2
RF3
RF4
RF5
RF6
0,40
0,45
0,50
0,55
0,60
0,65
0,70
0,75
0,80
0,85AUC score
Relevance Feeback size34861 RF
 34861 RFC
 31274 RF
 31274 RFC
 31702 RF
 31702 RFCFig. 6.Comparison of detailed results for 3 jobs with and without summaries of CL. For each job,RFCmeans AUC scores withCORTEXandRFwithoutCORTEX.
1134R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135Author&apos;s personal copyJoachims, T. (1997). A probabilistic analysis of the rocchio algorithm with tﬁdf for text categorization. InICML 1997, Nashville, Tennessee, USA(pp. 143–151).
San Francisco, CA, USA.
Kessler, R., Béchet, N., Roche, M., El-Bèze, M., &amp; Torres-Moreno, J. M. (2008a). Automatic proﬁling system for ranking candidates answers in human
resources. InOTM ’08 in Monterrey, Mexico(pp. 625–634).
Kessler, R., Béchet, N., Roche, M., El-Bèze, M., &amp; Torres-Moreno, J. M. (2009).Job offer management: How improve the ranking of candidates. Prague: ISMIS.
431–441.
Kessler, R., Torres-Moreno, J. M., &amp; El-Bèze, M. (2007). E-Gen: Automatic job offer processing system for human ressources. InMICAI, Aguscalientes, Mexique(pp. 985–995).
Kessler, R., Torres-Moreno, J. M., &amp; El-Bèze, M. (2008b). E-Gen: Proﬁlage automatique de candidatures. InTALN 2008, Avignon, France(pp. 370–379).
Loth, R., Battistelli, D., Chaumartin, F., De Mazancourt, H., Minel, J. L., &amp; Vinckx, A. (2010). Linguistic information extraction for job ads (SIRE project). InRIAO’2010 9th conference 28–30 April, Paris, France(pp. 300–303).
Marchal, E., Mellet, K., &amp; Rieucau, G. (2007). Job board toolkits: Internet matchmaking and changes in job advertisements.Human Relations, 60(7),
1091–1113.
Mocho, M., Paslaru, E., &amp; Simperl, B. (2006). Practical guidelines for building semantic e-recruitment applications. InI-Know’06 special track on advanced
semantic technologies, Graz, Austria, September 2006.
Morin, E., LeclFre, M., &amp; Trichet, F. (2004). The semantic web in e-recruitment. InThe ﬁrst European symposium of semantic Web (ESWS’2004)(pp. 67–78).
Quilan, J. (1993).C4.5: Programs for machine learning. San Mateo, CA, San Francisco, CA, USA: Morgan Kaufmann.
Rafter, R., Bradley, K., &amp; Smyt, B. (2000). Automated collaborative ﬁltering applications for online recruitment services. InInternational conference on adaptive
hypermedia and adaptive web-based systems, Trento, Italy(pp. 363–368).
Robertson, S., Walker, S., Jones, S., Hancock-Beaulieu, M. M., &amp; Gatford, M. (1994). Okapi at trec-3. NIST Special Publication 500-225: TREC-3, pp. 109–126.
Rocchio, J. (1971). Relevance feedback in information retrieval. InThe smart system: Experiments in automatic document processing(pp. 313–323). Prentice-
Hall.
Roche, M., &amp; Kodratoff, Y., 2006. Pruning terminology extracted from a specialized corpus for CV ontology acquisition. InOTM’06, Montpellier, France(pp.
1107–1116).
Roche, M., &amp; Prince, V. (2008). Evaluation et dTtermination de la pertinence pour des syntagmes candidats a la collocation. InJADT(pp. 1009–1020).
Salton, G., &amp; Buckley, C. (1990). Improving retrieval performance by relevance feedback.Journal of the American Society for Information Science, 288–297.
Salton, G., &amp; Mcgill, M. J. (1986).Introduction to modern information retrieval. New York, NY, USA: McGraw-Hill Inc.
Smyth, B., &amp; Bradley, K. (2003). Personalized information ordering: A case-study in online recruitment.Journal of Knowledge-Based Systems, 269–275.
Sparck Jones, K. (1970). Some thoughts on classiﬁcation for retrieval.Journal of Documentation, 89–101.
Sutton, R. S., &amp; Barto, A. G. (1998).Reinforcement learning: An introduction (adaptive computation and machine learning). The MIT Press.
Tolksdorf,
R.,
Mocho,
M.,
Heese,
R.,
Oldakowski,
R.,
&amp;
Christian,
B.
(2006).
Semantic-Web-Technologien
im
Arbeitsvermittlungsprozess.Wirtschaftsinformatik, 17–26.
Torres-Moreno, J. M., Velázquez-Morales, P., &amp; Meunier, M. (2001). CORTEX, un algorithme pour la condensation automatique de textes. InARCo(Vol. 2, pp.
365–371).
Torres-Moreno, J. M., St-Onge, P.-L., Gagnon, M., El-Bèze, M., &amp; Bellot, P. (2009). Automatic summarization system coupled with a question-answering
system (qaas). InCoRRabs/0905.2990.
Torres-Moreno, J. M., Velazquez-Morales, P., &amp; Meunier, J. (2002). Condensés de textes par des méthodes numériques.JADT, St Malo, France, 2, 723–734.
Viterbi, A. J. (1967). Error bounds for convolutional codes and an asymptotically optimal decoding algorithm.IEEE Transactions on Information Theory, 13,
260–269.
Yahiaoui, L., Boufaı¨da, Z., &amp; Prié, Y. (2006). Semantic annotation of documents applied to e-recruitment. InSWAP 2006 – Semantic web applications and
perspectives. ISSN: 1613-0073.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351135</biblio>
</article>
