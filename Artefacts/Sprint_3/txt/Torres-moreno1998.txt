Nom du Fichier :

Torres-moreno1998

Titre :

﻿ 

Auteurs :

LETTER  Communicated by Scott FahlmanEfficientAdaptive Learning for ClassificationTasks with Binary UnitsJ. Manuel Torres Moreno Mirta B. GordonDepartement´ de Recherche Fondamentale sur la Matier` e Condensee,´ CEA Grenoble, 38054 Grenoble Cedex 9, FranceThis article presents a new incremental learning algorithm for classi- fication tasks, called NetLines, which is well adapted for both binary and real-valued input patterns. It generates small, compact feedforward neuralnetworkswithonehiddenlayerofbinaryunitsandbinaryoutput units. A convergence theorem ensures that solutions with a finite num- ber of hidden units exist for both binary and real-valued input patterns. An implementation for problems with more than two classes, valid for any binary classifier, is proposed. The generalization error and the size of the resulting networks are compared to the best published resultsonwell-knownclassificationbenchmarks.Earlystoppingisshown to decrease overfitting, without improving the generalization perfor- mance.1 Introduction Feedforward neural networks have been successfully applied to the prob- lemoflearningpatternclassificationfromexamples.Therelationshipofthe numberofweightstothelearningcapacityandthenetwork’sgeneralization ability is well understood only for the simple perceptron, a single binary unitwhoseoutputisasigmoidalfunctionoftheweightedsumofitsinputs. In this case, efficientlearning algorithms based on theoretical results allow thedeterminationoftheoptimalweights.However,simpleperceptronscan generalize only those (very few) problems in which the input patterns are linearlyseparable(LS).Inmanyactualclassificationtasks,multilayeredper- ceptrons with hidden units are needed. However, neither the architecture (number of units, number of layers) nor the functions that hidden units havetolearnareknownapriori,andthetheoreticalunderstandingofthese networks is not enough to provide useful hints.Although pattern classificationis an intrinsically discrete task, it may be cast as a problem of function approximation or regression by assigning real values to the targets. This is the approach used by backpropagation andNeural Computation 10, 1007–1030 (1998) c 1998 Massachusetts Institute of Technology

Courriels :



Abstract :



Bibliographie :


